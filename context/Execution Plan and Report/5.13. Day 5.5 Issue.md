**Outstanding Issues**

- Cart contract still diverges from the published OpenAPI spec: responses omit required fields likeÂ id,Â subtotal,Â tax, andÂ itemCount, deletes return JSON instead of 204, and the documentedÂ /cart/bulk-importÂ endpoint is unimplemented. Any client generated from the spec will fail against the current API. (spec/openapi.yaml:195, spec/openapi.yaml:283, spec/openapi.yaml:787, backend/src/cart/cart.controller.ts:12, backend/src/cart/cart.controller.ts:36, backend/src/cart/cart.service.ts:126)
	- After codex => CSV importing currently assumes simple comma-separated values without quoted commas; extend parsing or add validation tests if real data needs that flexibility. Natural next step: add automated tests for the new bulk import workflow to lock down the spec-aligned behavior.

- Category hierarchy support promised in the spec is stubbed out;Â parentIdÂ queries simply return an empty array because the Prisma model has no parent linkage, level, or product count fields. Consumers expecting hierarchical navigation and counts cannot use the current data. (spec/openapi.yaml:172, spec/openapi.yaml:715, backend/src/categories/categories.service.ts:8, backend/prisma/schema.prisma:24)
	- After codex => Apply the new migration (npx prisma migrate deploy) and reseed after updating your database to pick up the hierarchy.

- Role and tier enumerations drift from the API contract: the spec lists rolesÂ ADMIN|PURCHASER|VIEWER|SALESÂ and company tiersÂ STANDARD|BRONZE|SILVER|GOLD, but the code usesÂ ADMIN|APPROVER|PURCHASER|USERÂ and seeds a company with tierÂ ADMIN, so responses violate the documented enums. (spec/openapi.yaml:693, spec/openapi.yaml:709, backend/prisma/schema.prisma:162, backend/prisma/seed.ts:31)
	-  After codex => 
		- UpdatedÂ prisma/seed.tsÂ to use the new category hierarchy correctly (connecting parents instead of assigningÂ parentId) and kept role/tier values aligned with the refreshed enums. Seeding now matches the revised schema.
		- Consolidated the schema evolution into a single migrationÂ 20251001085312_update_role_enum_and_category_hierarchy, adding the category hierarchy columns/constraints and replacing the Role enum withÂ ADMIN|PURCHASER|VIEWER|SALES. Removed the old manual migration stubs to avoid duplicate history.
		- Regenerated the Prisma client so TypeScript knows about the new fields/enums, and ran the migration plusÂ npx prisma db seedÂ to confirm the database seeds cleanly with the updated data.

- Product payloads lack several required fields from the spec (descriptionEn,Â descriptionTh,Â specifications,Â images), and the database stores only a singleÂ description, so OpenAPI-based clients or validators will report schema errors. (spec/openapi.yaml:734, backend/prisma/schema.prisma:100, backend/src/products/dto/create-product.dto.ts:4)
	-  After codex => RunÂ npx prisma migrate deploy && npx prisma db seedÂ in any other environment to apply the schema changes, and consider adding UI cues for invalid specifications input since the editor now expects JSON.

- Align backend to published API contract: add globalÂ /apiÂ prefix, implement refresh token route, categories controller, full product filters, and cart endpoint shapes; update Next.js env usage and smoke tests to the same base URL. Guard with integration tests that mirror the Playthrough requests (context/Execution Plan and Report/5.10. Day 5.5 HIGH PRIORITY OpenAPI Specification vs Implementation Mismatch.md:1).
	- Tests:Â npm run test:e2eÂ (backend)
	- Next steps (optional): 
		1) Wire the new e2e suite into CI once youâ€™re ready to spin up a real Postgres/Redis pair for automated runs. 
		2) Layer in real Prisma fixtures for these tests when you want to exercise the full persistence flow instead of the current service stubs.
	- which guided the checklist coverage chosen for the e2e validations.
	- Tests: ranÂ docker compose up -d postgres redisÂ followed byÂ npm run test:e2eÂ (backend).
		- Next steps (optional):
			1. Monitor the new CI job; if migrations become redundant, setÂ SKIP_E2E_MIGRATIONS=trueÂ in that step after a dedicated migrate stage.
			2. Expand the fixture builder to cover admin endpoints or orders once you want broader smoke coverage.

- Harden authentication and admin surfaces: introduce role-based guard + decorators, DTO validation, and consistent error responses so only admin roles manage catalog data, and the auth flows in the checklist surface meaningful feedback (context/Execution Plan and Report/5.11. Day 5.5 HIGH PRIORITY Unauthorized Product Management APIs.md:1;Â context/Execution Plan and Report/5.12. Day 5.5 MEDIUM PRIORITY Poor Error Handling in Registration.md:1).
	- - npm run testÂ (backend unit suite)
- npm run test:e2eÂ (backend playthrough against live Postgres/Redis)

- Streamline boot & seed workflow: reconcile port expectations, addÂ .envÂ templates, npm scripts (or aÂ make playthrough) to run compose, migrations, seed, and start both apps with matching API URLs to eliminate the port mismatch noted in the retros (context/NCS B2B E-Commerce Platform â€“ MonthÂ 1 Execution Plan (Docker Compose Edition).docx:1;Â context/Execution Plan and Report/5.9. Day 5.5 HIGH PRIORITY Port Mismatch Between Frontend and Backend.md:1).
	- 

- Document admin/API smoke steps: extend the Playthrough checklist with curl/Postman samples for admin overview, tier updates, and cart CSV import so the non-UI endpoints are validated alongside UI flows; include expected seeded accounts/products from the Prisma seed script reference (context/Execution Plan and Report/0.0.1. Week 1 Execution Report.md:1).














Everything in the repo is demo-ready: backend routes match the technical blueprint, the Docker-backed Postgres/Redis stack seeds correctly, and the frontend consumes theÂ /apiÂ endpoints documented in the Monthâ€‘1 plan. Use the flow below to spin it up and verify the full integration.

**Terminal Commands**

1. **Pre-flight (run in repo root)**
    
    `node -v # expect â‰¥18 npm -v docker info # ensure Docker Desktop is running lsof -i :3000 -sTCP:LISTEN # should return nothing (free port) lsof -i :3100 -sTCP:LISTEN # new default frontend port`
    
2. **Prepare env & dependencies (one-off)**
    
    `cp .env.example .env docker compose pull postgres redis`
    
3. **Launch the integrated demo**
    
    `./scripts/playthrough.sh`
    
    What happens automatically:
    
    - docker compose up -d postgres redis
    - PGÂ health waits untilÂ pg_isreadyÂ succeeds
    - BackendÂ npm install,Â npm run db:migrate,Â npm run db:seed,Â npm run start:devÂ (port 3000)
    - FrontendÂ npm install,Â npm run dev -- --port 3100Â withÂ NEXT_PUBLIC_API_URL=http://localhost:3000/api
    
    Frontend stays attached in the terminal; hitÂ Ctrl+CÂ when youâ€™re done. Docker services stop unless you setÂ KEEP_SERVICES=true.
    
4. **Optional confidence checks (new shell)**
    
    `curl http://localhost:3000/api/health cd frontend && NEXT_PUBLIC_API_URL=http://localhost:3000/api npm run smoke cd backend && npm run test && npm run test:e2e`
    
5. **Clean up after the demo**
    
    `docker compose down`
    

**Deep-Dive Checklist**

- â˜Â **Environment ready**
    
    - Confirm Node â‰¥18, npm â‰¥9.
    - Docker Desktop running andÂ docker infoÂ succeeds.
    - Ports 3000 (backend) and 3100 (frontend) free before starting.
- â˜Â **Playthrough script completes**
    
    - Console shows â€œWaiting for Postgres to accept connectionsâ€ followed by â€œNest application successfully startedâ€ andÂ ğŸš€ NCS Backend API running on http://localhost:3000/api.
    - Frontend terminal shows â€œNext.js â€¦ Readyâ€ onÂ [http://localhost:3100](http://localhost:3100/).
- â˜Â **Frontend demo ([http://localhost:3100](http://localhost:3100/))**
    
    1. Navigate to â€œAuthenticateâ€.
    2. Log in withÂ admin@ncs.co.thÂ /Â admin123.
        - Expected: status line reports token expiry, JSON response preview shows access/refresh tokens.
    3. Catalog list displays seeded products (â€œSW-24P-1Gâ€, â€œRT-ENT-5Gâ€, etc.).
    4. Add to cart, adjust quantities, clear cartâ€”all reflect totals with VAT.
- â˜Â **Admin/API smoke (curl or Postman)**
    
    1. Login (reuse token for the steps below):
        
        `TOKEN=$(curl -s -X POST http://localhost:3000/api/auth/login \ -H "Content-Type: application/json" \ -d '{"email":"admin@ncs.co.th","password":"admin123"}' | jq -r .accessToken)`
        
    2. Overview metrics:
        
        `curl http://localhost:3000/api/admin/overview -H "Authorization: Bearer $TOKEN"`
        
    3. Company tier update:
        
        `curl -X PUT http://localhost:3000/api/admin/companies/test-company-id/tier \ -H "Authorization: Bearer $TOKEN" \ -H "Content-Type: application/json" \ -d '{"tier":"PLATINUM"}'`
        
    4. Cart bulk import (buyer context):
        
        `printf 'productId,quantity\nsw-24p-1g-id,2\nrt-ent-5g-id,1\n' > /tmp/cart.csv curl -X POST http://localhost:3000/api/cart/bulk-import \ -H "Authorization: Bearer $TOKEN" \ -F file=@/tmp/cart.csv`
        
    5. Verify cart contents:
        
        `curl http://localhost:3000/api/cart -H "Authorization: Bearer $TOKEN"`
        
    6. Inventory search:
        
        `curl "http://localhost:3000/api/admin/products?search=SW" \ -H "Authorization: Bearer $TOKEN"`
        
- â˜Â **Why it works**
    
    - Prisma migrations seed the catalog, companies, and users exactly as documented in the Technical Design (seeÂ backend/prisma/seed.ts).
    - Routes and guards align with the Execution Planâ€™s requirements: globalÂ /apiÂ prefix, JWT auth, and role checks around admin surfaces.
    - Frontend readsÂ NEXT_PUBLIC_API_URLÂ for every API call, so changing ports/env is centralized.
    - Playthrough script detects Postgres readiness before hitting Prisma, eliminating the P1001 errors we saw earlier.
- â˜Â **If anything fails**
    
    - Backend health check fails â†’ inspect backend terminal; restartÂ ./scripts/playthrough.sh.
    - Frontend 404 onÂ /api/productsÂ â†’ ensure backend still running on port 3000; rerun curl health check.
    - CSV import error â†’ verify file format (headersÂ productId,quantity) and product IDs from seed file.
- â˜Â **After demo**
    
    - Stop frontend withÂ Ctrl+C.
    - Script cleanly shuts down backend and Docker. If you need the data for another session, leave services running viaÂ KEEP_SERVICES=true.

Follow this checklist each time, and the backend/frontend will stay in sync with the architecture outlined in the context docs.